
Running configs.
{'root_path': 'datasets', 'dataset': 'eurosat', 'shots': 16, 'backbone': 'RN50', 'n_prompt_tokens': 4, 'intrinsic_dim': 512, 'budget': 8000, 'bound': 5, 'alpha': 1, 'popsize': 40, 'parallel': False, 'print_every': 50, 'eval_every': 100, 'n': 1, 'batch_size': 256, 'std': 1, 'weight': 0.01, 'train_epoch': 20, 'subsample_classes': 'all', 'seed': 1}

Preparing dataset.
Reading split from /raid0-data/yifan/datasets/eurosat/split_zhou_EuroSAT.json
Creating a 16-shot dataset

Loading visual features and labels from test set.
Initial context: "a photo of a"
Number of context words (tokens): 4
Population Size: 40
Serial Evaluation.
Printing trainable parameters
Printing to verify trainable parameters
name input_param param.shape: torch.Size([40, 512])
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.51it/s]
/home/yifanyang/miniconda3/envs/vlm/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Steps: 0 	 Acc:48.23456790123457 	 Loss:0
merge the parameter at step 1
> /home/yifanyang/tmp/mllm/neurips_code/main_sharpzo.py(495)run()
-> loss = zo_trainer.zo_step(
torch.Size([512])
*** NameError: name 'self' is not defined
*** NameError: name 'prompt_leaner' is not defined
<generator object Module.named_parameters at 0x713fb04ed040>
[torch.Size([512]), torch.Size([77, 512]), torch.Size([512, 512]), torch.Size([]), torch.Size([768]), torch.Size([197, 768]), torch.Size([768, 512]), torch.Size([768, 3, 16, 16]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([2304, 768]), torch.Size([2304]), torch.Size([768, 768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([3072, 768]), torch.Size([3072]), torch.Size([768, 3072]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([768]), torch.Size([1536, 512]), torch.Size([1536]), torch.Size([512, 512]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([2048, 512]), torch.Size([2048]), torch.Size([512, 2048]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([1536, 512]), torch.Size([1536]), torch.Size([512, 512]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([2048, 512]), torch.Size([2048]), torch.Size([512, 2048]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([1536, 512]), torch.Size([1536]), torch.Size([512, 512]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([2048, 512]), torch.Size([2048]), torch.Size([512, 2048]), torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([1536, 512]), torch.Size([1536]),
