
Running configs.
{'root_path': 'datasets', 'dataset': 'eurosat', 'shots': 16, 'backbone': 'RN50', 'n_prompt_tokens': 4, 'intrinsic_dim': 512, 'budget': 8000, 'bound': 5, 'alpha': 1, 'popsize': 40, 'parallel': False, 'print_every': 50, 'eval_every': 100, 'n': 1, 'batch_size': 256, 'std': 1, 'weight': 0.01, 'train_epoch': 20, 'subsample_classes': 'all', 'seed': 1}

Preparing dataset.
Reading split from /raid0-data/yifan/datasets/eurosat/split_zhou_EuroSAT.json
Creating a 16-shot dataset

Loading visual features and labels from test set.
Initial context: "a photo of a"
Number of context words (tokens): 4
Population Size: 40
Serial Evaluation.
Printing trainable parameters
Printing to verify trainable parameters
name input_param param.shape: torch.Size([40, 512])
Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]
    1     40 1.662860870361328e+00 1.0e+00 3.92e-01  4e-01  4e-01 0:07.7
/home/yifanyang/miniconda3/envs/vlm/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Steps: 0 	 Acc:48.23456790123457 	 Loss:0
    2     80 1.637218832969666e+00 1.0e+00 3.86e-01  4e-01  4e-01 0:15.2
Steps: 1 	 Acc:48.23456790123457 	 Loss:0
    3    120 1.546686887741089e+00 1.0e+00 3.80e-01  4e-01  4e-01 0:22.6
Steps: 2 	 Acc:48.23456790123457 	 Loss:0
    4    160 1.579167008399963e+00 1.0e+00 3.75e-01  4e-01  4e-01 0:30.2
Steps: 3 	 Acc:48.23456790123457 	 Loss:0
    5    200 1.563799142837524e+00 1.0e+00 3.70e-01  4e-01  4e-01 0:37.7
Steps: 4 	 Acc:48.23456790123457 	 Loss:0
    6    240 1.519938468933105e+00 1.0e+00 3.65e-01  4e-01  4e-01 0:45.1
Steps: 5 	 Acc:48.23456790123457 	 Loss:0
    7    280 1.457567453384399e+00 1.0e+00 3.61e-01  4e-01  4e-01 0:52.7
Steps: 6 	 Acc:48.23456790123457 	 Loss:0
