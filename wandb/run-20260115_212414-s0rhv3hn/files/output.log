
Running configs.
{'root_path': 'datasets', 'dataset': 'eurosat', 'shots': 16, 'backbone': 'RN50', 'n_prompt_tokens': 4, 'intrinsic_dim': 512, 'budget': 8000, 'bound': 5, 'alpha': 1, 'popsize': 40, 'parallel': False, 'print_every': 50, 'eval_every': 100, 'n': 1, 'batch_size': 256, 'std': 1, 'weight': 0.01, 'train_epoch': 20, 'subsample_classes': 'all', 'seed': 1}

Preparing dataset.
Reading split from /raid0-data/yifan/datasets/eurosat/split_zhou_EuroSAT.json
Creating a 16-shot dataset

Loading visual features and labels from test set.
Initial context: "a photo of a"
Number of context words (tokens): 4
Population Size: 40
Serial Evaluation.
Printing trainable parameters
Printing to verify trainable parameters
name input_param param.shape: torch.Size([40, 512])
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 69.91it/s]
/home/yifanyang/miniconda3/envs/vlm/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Steps: 0 	 Acc:48.23456790123457 	 Loss:0
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.75it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.73it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.69it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.73it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.78it/s]
Steps: 5 	 Acc:56.02469135802469 	 Loss:0
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.64it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.87it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.48it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.01it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.96it/s]
Steps: 10 	 Acc:59.28395061728395 	 Loss:0
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.40it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 70.58it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 512/512 [00:07<00:00, 71.02it/s]
 21%|█████████████████▌                                                                 | 108/512 [00:01<00:05, 71.22it/s]
